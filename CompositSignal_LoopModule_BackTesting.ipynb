{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f88c27c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:14:56.611589Z",
     "start_time": "2024-06-17T04:14:55.567316Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1b2bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:21:58.534975Z",
     "start_time": "2024-06-17T04:21:58.527975Z"
    }
   },
   "outputs": [],
   "source": [
    "hgyz_signals = ['zyhgitt', 'zcqlb', 'srclyoy', 'xckpmiidy', 'tb10y_diff', 'tb10y_ttm', 'nrfs']\n",
    "jszb_signals = ['roc', 'sma', 'dma', 'dma_ama', 'macd', 'trix', 'bbi', 'bbands', 'cci', 'kdj', 'rsi', 'cmo']\n",
    "qx_signals = ['bbands_rzmr', 'bbands_iccfe', 'bbands_ifcfe', 'volumeratio', 'oiratio']\n",
    "factors_signals = ['zyhgitt', 'zcqlb', 'srclyoy', 'xckpmiidy', 'tb10y_diff', 'tb10y_ttm', 'nrfs', 'roc', 'sma', 'dma', 'dma_ama', 'macd', 'trix', 'bbi', 'bbands', 'cci', 'kdj', 'rsi', 'cmo', 'bbands_rzmr', 'bbands_iccfe', 'bbands_ifcfe', 'volumeratio', 'oiratio']\n",
    "# factors_signals_delvol = ['zyhgitt','zcqlb','srclyoy','xckpmiidy','tb10y_diff','tb10y_ttm','nrfs','roc','sma','dma','dma_ama','macd','trix','bbi','bbands','cci','kdj','rsi','cmo','bbands_rzmr','bbands_iccfe','bbands_ifcfe','oiratio']\n",
    "\n",
    "# backtesting period configuration\n",
    "fromdate = datetime.datetime(2024, 6, 10)\n",
    "todate = datetime.datetime(2024, 6, 17)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8c8f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:14:59.318499Z",
     "start_time": "2024-06-17T04:14:59.256813Z"
    }
   },
   "outputs": [],
   "source": [
    "def kelly_criterion(p, b):\n",
    "    q = 1 - p\n",
    "    f_star = (b * p - q) / b if (b * p - q) / b > 0 else 0\n",
    "    return f_star\n",
    "\n",
    "\n",
    "def draw_sng(nv_stg, nv_index, text=''):\n",
    "    \"\"\"\n",
    "\n",
    "    :param nv_index:\n",
    "    :param nv_stg:\n",
    "    :type text: str\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.plot(nv_stg, label='nv_stg')\n",
    "    ax.plot(nv_index, label='nv_index')\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_title('策略&基准净值走势', fontsize='x-large')\n",
    "    ax.set_xlabel(\"{}\\n{}\".format('year', text), fontsize=10, fontfamily='sans-serif', fontstyle='italic')\n",
    "    ax.set_ylabel(ylabel='', fontsize=10, fontstyle='oblique')\n",
    "\n",
    "    ax.xaxis.set_tick_params(rotation=45, labelsize=10, colors='black')\n",
    "    ax.set_ylim(bottom=0)\n",
    "\n",
    "\n",
    "def ratio_analyze(nv_stg, position, timeperiod='d', rf=0):\n",
    "    # 计算每日收益率\n",
    "    ret = nv_stg.pct_change(1) * 100\n",
    "\n",
    "    # 根据时间周期计算年化收益率和年化波动率\n",
    "    try:\n",
    "        if timeperiod == 'd':\n",
    "            periods_per_year = 252\n",
    "        elif timeperiod == 'm':\n",
    "            periods_per_year = 12\n",
    "        elif timeperiod == 'w':\n",
    "            periods_per_year = 52\n",
    "        else:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        raise ValueError(\"timeperiod 参数必须是 'd'（日）、'm'（月）或 'w'（周）\")\n",
    "\n",
    "    anl_ret = (np.power(nv_stg.iloc[-1], periods_per_year / len(nv_stg)) - 1) * 100\n",
    "    vol = np.sqrt(periods_per_year) * np.std(ret)\n",
    "\n",
    "    # 计算最大回撤率\n",
    "    mdd_r = ((nv_stg.cummax() - nv_stg) / nv_stg.cummax()).max() * 100\n",
    "\n",
    "    # 计算夏普比率\n",
    "    sharp = (anl_ret - rf) / vol\n",
    "\n",
    "    # 计算换手率/调仓率（双边）\n",
    "    list_item = [list(v) for k, v in itertools.groupby(position.values)]\n",
    "    turnover = len(list_item) / (len(nv_stg) / periods_per_year)\n",
    "\n",
    "    # 计算cagr/vol比率\n",
    "    cagr_vol = anl_ret / vol\n",
    "\n",
    "    # 输出结果\n",
    "    ratio_txt = (\n",
    "        \"复合年化收益率：{:.2f}%；年化波动率：{:.2f}；最大回撤率：{:.2f}%；\"\n",
    "        \"夏普比：{:.2f}；换手率/调仓率（双边）：{:.2f}；cagr/vol：{:.2f}\"\n",
    "    ).format(anl_ret, vol, mdd_r, sharp, turnover, cagr_vol)\n",
    "\n",
    "    return ratio_txt\n",
    "\n",
    "\n",
    "# 通过signal拿到了一个df position\n",
    "def get_position(df_signal, barShifted=1):\n",
    "    # 通过signal获取series position\n",
    "    series = df_signal.values\n",
    "    list_position = [0 for _ in range(barShifted)]\n",
    "    # list_position.extend([0]*(len(roc_signal['signal'])))\n",
    "    for i, signal in enumerate(series):\n",
    "        if signal == 1:\n",
    "            list_position.append(1)\n",
    "        elif signal == -1:\n",
    "            list_position.append(0)\n",
    "        else:\n",
    "            list_position.append(list_position[-1])\n",
    "    # from list to series\n",
    "    series_posiiton = pd.Series(list_position)\n",
    "    series_posiiton.name = 'position'\n",
    "    # from series to df，附加日期\n",
    "    df_position = pd.merge(left=series_posiiton, right=df_signal.reset_index(), left_index=True, right_index=True, how='left')[['Date', 'position']]\n",
    "\n",
    "    return df_position\n",
    "\n",
    "\n",
    "# 移动signal，根据历史数据获得当期signal值\n",
    "def get_current_signal(df_signal, barShifted=1):\n",
    "    # 判断period\n",
    "    length = len(df_signal) / ((df_signal.index[-1] - df_signal.index[0]).days / 365)\n",
    "    period = 12 if length < 20 else 52 if 20 < length < 100 else 250\n",
    "\n",
    "    # get datetime index[-1]\n",
    "    if period == 12:\n",
    "        next_month = pd.date_range(start=df_signal.index[-1], periods=3, freq='M')[-2:]\n",
    "        concat_data = pd.DataFrame(next_month)\n",
    "    elif period == 52:\n",
    "        next_week = pd.date_range(start=df_signal.index[-1], periods=3, freq='W-SUN')[-2:]\n",
    "        concat_data = pd.DataFrame(next_week)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_signal = pd.concat([df_signal, concat_data])\n",
    "    df_signal_ = df_signal['signal'].shift(2)\n",
    "\n",
    "    return df_signal_\n",
    "\n",
    "\n",
    "def get_bm(freq, table_name='881001_wi', indicator_name='ret'):\n",
    "    def toweek_inclusive(df):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df_ = df.resample('W-SUN').last().ffill().dropna()  # resample用前最邻近值\n",
    "        return df_\n",
    "\n",
    "    def tomonth_inclusive(df):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df_ = df.resample('M').last().ffill().dropna()  # resample用前最邻近值\n",
    "        return df_\n",
    "\n",
    "    engine = create_engine(\"mysql+pymysql://root:@localhost:3306/meta_data?charset=utf8mb4\")\n",
    "    if table_name == '881001_wi':\n",
    "        df = pd.read_sql('SELECT Date,HIGH,LOW,CLOSE FROM {}'.format(table_name), engine, index_col='Date')  # 从meta_data提取数据\n",
    "    elif table_name == 'cba00101_cs':\n",
    "        df = pd.read_sql('SELECT Date,CLOSE FROM {}'.format(table_name), engine, index_col='Date')  # 从meta_data提取数据\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if freq == 'M':\n",
    "        df_ = tomonth_inclusive(df)\n",
    "    elif freq == 'W-SUN':\n",
    "        df_ = toweek_inclusive(df)\n",
    "    else:\n",
    "        df_ = df.copy()\n",
    "        df_.index = pd.to_datetime(df_.index)\n",
    "\n",
    "    df_['ret'] = df_['CLOSE'].pct_change(1)\n",
    "    return df, df_, df_[indicator_name]\n",
    "\n",
    "\n",
    "def get_net_value(df_position, fromdate, todate,benchmark_map):\n",
    "    # get frequency\n",
    "    length = len(df_position) / ((df_position[df_position['Date'].notna()]['Date'].iat[-1] - df_position['Date'].iat[0]).days / 365)\n",
    "    period = 12 if length < 20 else 52 if 20 < length < 100 else 250\n",
    "\n",
    "    # 根据频率获取基准收益率\n",
    "    right = benchmark_map[period]\n",
    "\n",
    "    df_position_ = pd.merge(left=df_position, right=right, left_on='Date', right_on='Date', how='left').set_index('Date')\n",
    "\n",
    "    # calculate net value\n",
    "    df_ = df_position_[(df_position_.index >= fromdate) & (df_position_.index <= todate)]  # 切回测区间，包含首尾\n",
    "    df_.iloc[0] = 0  # 设置day1 ret=0\n",
    "    df_.loc[:, 'nv_idc'] = (df_.ret * df_.loc[:, 'position'] + 1.0).cumprod()  # 计算因子净值\n",
    "    df_.loc[:, 'nv_bm'] = (df_.ret + 1.0).cumprod()  # 计算基准净值\n",
    "    return df_[['nv_idc', 'nv_bm']]\n",
    "\n",
    "\n",
    "# 获得加权指标-->数据处理-->获得权重\n",
    "def linear_weighting(dic, how='e', is0neThird=False, solver='MMS', ispositive=False, fromdate=fromdate, todate=todate, rf=0, hgyz_signals=hgyz_signals, jszb_signals=jszb_signals, qx_signals=qx_signals):\n",
    "    def get_sharp(k, df_nv, dic_ratio):  # 夏普比率函数\n",
    "        ret = np.power(df_nv.iloc[-1, 0], period / len(df_nv)) - 1\n",
    "        vol = np.sqrt(period) * np.std(df_nv.iloc[:, 0].pct_change(1) * 100)\n",
    "        if not vol:\n",
    "            return  # 如果 vol 为零，直接返回\n",
    "        dic_ratio[k] = (ret - rf) / vol\n",
    "        if ispositive:\n",
    "            dic_ratio = {key: dic_ratio[key] for key in dic_ratio.keys() if dic_ratio[key] > 0}\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def get_cagrvol(k, df_nv, dic_ratio):  # cagr/vol 函数\n",
    "        ret = np.power(df_nv.iloc[-1, 0], period / len(df_nv)) - 1\n",
    "        vol = np.sqrt(period) * np.std(df_nv.iloc[:, 0].pct_change(1) * 100)\n",
    "        if not vol:\n",
    "            return  # 如果 vol 为零，直接返回\n",
    "        dic_ratio[k] = ret / vol\n",
    "        if ispositive:\n",
    "            dic_ratio = {key: dic_ratio[key] for key in dic_ratio.keys() if dic_ratio[key] > 0}\n",
    "        else:\n",
    "            dic_ratio = dic_ratio\n",
    "\n",
    "    def min_max_scaler(dic):  # scaler函数\n",
    "        v_min = min(dic.values())\n",
    "        v_max = max(dic.values())\n",
    "        for k, value in dic.items():\n",
    "            dic[k] = (value + 1 - v_min) / (v_max - v_min) if len(dic) > 1 else 1  # 三元表达\n",
    "        return dic\n",
    "\n",
    "    def get_weighted(dic, solver='ASONE'):  # 获取权重。ASONE：所有因子低位同等；1/3_e：1/3 * 因子内部等权\n",
    "\n",
    "        def get_weighted_asone(dic):\n",
    "            sum_v = sum(dic.values())\n",
    "            for k, v in dic.items():\n",
    "                dic[k] = v / sum_v\n",
    "            return dic\n",
    "\n",
    "        if solver == 'ASONE':\n",
    "            dic = get_weighted_asone(dic)\n",
    "\n",
    "        elif solver == '1/3_e':\n",
    "            for lst in [hgyz_signals, jszb_signals, qx_signals]:\n",
    "                temp_weight = get_weighted_asone({key: dic[key] for key in dic.keys() if key in lst})\n",
    "                for k, v in temp_weight.items():\n",
    "                    dic[k] = 1 / 3 * v\n",
    "        else:\n",
    "            pass\n",
    "        return dic\n",
    "\n",
    "    dic_ratio = {}  # key：因子名；value：ratio(等权时为1)\n",
    "\n",
    "    # key：因子名称；value:指标\n",
    "    for k, df_nv in dic.items():\n",
    "        # 获取因子对应的period\n",
    "        length = len(df_nv) / ((todate - fromdate).days / 365)\n",
    "        period = 12 if length < 20 else 52 if 20 < length < 100 else 250\n",
    "        # 根据方法形成指标字典\n",
    "        if how == 'e':\n",
    "            dic_ratio[k] = 1\n",
    "        elif how == 's':\n",
    "            get_sharp(k, df_nv, dic_ratio)\n",
    "        elif how == 'c':\n",
    "            get_cagrvol(k, df_nv, dic_ratio)\n",
    "\n",
    "    # 根据因子、指标获取权重\n",
    "    if how == 'e':\n",
    "        if is0neThird:\n",
    "            weight = get_weighted(dic_ratio, solver='1/3_e')\n",
    "        weight = get_weighted(dic_ratio)\n",
    "\n",
    "    else:\n",
    "        if solver == 'MMS':\n",
    "            scaled_dic_ratio = min_max_scaler(dic_ratio)\n",
    "            if is0neThird:\n",
    "                weight = get_weighted(scaled_dic_ratio, solver='1/3_e')\n",
    "            weight = get_weighted(scaled_dic_ratio)\n",
    "        else:\n",
    "            pass\n",
    "    return weight\n",
    "\n",
    "\n",
    "def calculate_composite_signal(dic_position, benchmark_map,is0neThird=True, freq='W-SUN', fromdate=fromdate, todate=todate, factors_signals=factors_signals):\n",
    "    \"\"\"\n",
    "    计算组合信号并进行回测\n",
    "    :param fromdate: 回测开始日期\n",
    "    :param todate: 回测结束日期\n",
    "    :param factors_signals: 因子信号列表\n",
    "    :param dic_position: 因子仓位字典\n",
    "    :param linear_weighting_func: 线性加权函数\n",
    "    :param is0neThird: 线性加权函数参数，默认True\n",
    "    :param freq: 回测频率，默认每周一次\n",
    "    :return: 回测结果\n",
    "    \"\"\"\n",
    "    # 创建回测区间序列\n",
    "    backtesting_period = pd.date_range(start=fromdate, end=todate, freq=freq)\n",
    "    engine = create_engine(\"mysql+pymysql://root:@localhost:3306/factors_signal?charset=utf8mb4\")  # 创建数据库连接\n",
    "    results = pd.DataFrame()  # 初始化缓存结果\n",
    "    results_backtesting = pd.DataFrame()  # 初始化回测结果\n",
    "\n",
    "    for i, todate_ in enumerate(tqdm(backtesting_period, desc='PROCESSING')):\n",
    "        next_day_ = todate_ + datetime.timedelta(days=1)  # 初始化信号日期\n",
    "        fromdate_ = todate_ - datetime.timedelta(days=360)  # 初始化业绩回测起始日期\n",
    "\n",
    "        # 计算因子净值\n",
    "        dic_all_net_value = {\n",
    "            factor_name: get_net_value(dic_position[factor_name], fromdate_, todate_,benchmark_map)\n",
    "            for factor_name in factors_signals\n",
    "        }\n",
    "\n",
    "        # 筛选具有绝对收益的因子\n",
    "        list_filtered_factor = [\n",
    "            key for key in dic_all_net_value.keys()\n",
    "            if dic_all_net_value[key]['nv_idc'].iat[-1] > dic_all_net_value[key]['nv_bm'].iat[-1] or key == 'zcqlb'\n",
    "        ]\n",
    "\n",
    "        # 从数据库中提取信号\n",
    "        results_ = pd.DataFrame()\n",
    "        for table in list_filtered_factor:\n",
    "            query = f\"SELECT `signal` FROM {table} WHERE `Date` BETWEEN '{fromdate_.strftime('%Y-%m-%d')}' AND '{todate_.strftime('%Y-%m-%d')}' ORDER BY `Date` DESC LIMIT 1\"\n",
    "            df = pd.read_sql(query, engine)\n",
    "            df.rename(columns={'signal': table}, inplace=True)\n",
    "            results_ = pd.concat([results_, df], axis=1)\n",
    "\n",
    "        # 插入信号日期\n",
    "        results_.insert(0, 'Date', next_day_)\n",
    "\n",
    "        # 对筛选出的因子赋权\n",
    "        dic_filtered_net_value = {key: dic_all_net_value[key] for key in list_filtered_factor}\n",
    "        weight = pd.DataFrame(linear_weighting(dic_filtered_net_value, is0neThird=is0neThird), index=[0])\n",
    "        results_['bullish_probability'] = results_.apply(\n",
    "            lambda row: sum(row[keys] * weight[keys] if row[keys] > 0 else 0.5 * weight[keys] if row[keys] == 0 else 0 for keys in weight.keys()), axis=1\n",
    "        )\n",
    "\n",
    "        # 合并结果\n",
    "        combine_results_ = pd.concat([results_, weight], axis=0)\n",
    "        results = pd.concat([results, combine_results_], axis=0)\n",
    "        results_backtesting = pd.concat([results_backtesting, results_], axis=0)\n",
    "\n",
    "        # 将 'bullish_probability' 列移动到最后一列\n",
    "        cols = list(results.columns)\n",
    "        cols.append(cols.pop(cols.index('bullish_probability')))\n",
    "        results = results[cols]\n",
    "        results_backtesting = results_backtesting[cols]\n",
    "\n",
    "    engine.dispose()\n",
    "    return results, results_backtesting\n",
    "\n",
    "\n",
    "# 下面这个是回测用\n",
    "# FIXME:这个func还没做完，下次用了再优化\n",
    "def backtest_composite_signals(fromdate, todate, benchmark_map, factors_signals, dic_position, linear_weighting_func, is0neThird=True):\n",
    "    \"\"\"\n",
    "    回测组合信号\n",
    "    :param fromdate: 回测开始日期\n",
    "    :param todate: 回测结束日期\n",
    "    :param db_url: 数据库连接URL\n",
    "    :param factors_signals: 因子信号列表\n",
    "    :param dic_position: 因子仓位字典\n",
    "    :param linear_weighting_func: 线性加权函数\n",
    "    :param is0neThird: 线性加权函数参数，默认True\n",
    "    :return: 回测结果\n",
    "    \"\"\"\n",
    "    # 创建回测区间序列\n",
    "    backtesting_period = pd.date_range(start=fromdate, end=todate, freq='D')\n",
    "    df_result_position = pd.DataFrame(index=backtesting_period)\n",
    "\n",
    "    # 合并因子仓位\n",
    "    for k, v in dic_position.items():\n",
    "        v_ = v.set_index('Date')\n",
    "        v_.rename(columns={'position': f'{k}_position'}, inplace=True)\n",
    "        df_result_position = pd.merge(left=df_result_position, right=v_, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # 填充缺失值\n",
    "    df_result_position.bfill(inplace=True)\n",
    "    df_result_position.ffill(inplace=True)\n",
    "\n",
    "    results = pd.DataFrame()  # 初始化缓存结果\n",
    "    results_backtesting = pd.DataFrame()  # 初始化回测结果\n",
    "\n",
    "    for i, todate_ in enumerate(tqdm(backtesting_period, desc='PROCESSING')):\n",
    "        next_day_ = todate_ + datetime.timedelta(days=1)  # 初始化信号日期\n",
    "        fromdate_ = todate_ - datetime.timedelta(days=360)  # 初始化业绩回测起始日期\n",
    "\n",
    "        # 计算因子净值\n",
    "        dic_all_net_value = {\n",
    "            factor_name: get_net_value(dic_position[factor_name], fromdate_, todate_,benchmark_map)\n",
    "            for factor_name in factors_signals\n",
    "        }\n",
    "\n",
    "        # 筛选具有绝对收益的因子\n",
    "        list_filtered_factor = [\n",
    "            key for key in dic_all_net_value.keys()\n",
    "            if dic_all_net_value[key]['nv_idc'].iat[-1] > dic_all_net_value[key]['nv_bm'].iat[-1] or key == 'zcqlb'\n",
    "        ]\n",
    "\n",
    "        # 从 df_result_position 中提取仓位\n",
    "        results_ = pd.DataFrame()\n",
    "        for item in list_filtered_factor:\n",
    "            df = pd.DataFrame([df_result_position.loc[next_day_, f'{item}_position']], index=[0], columns=[item])\n",
    "            results_ = pd.concat([results_, df], axis=1)\n",
    "\n",
    "        # 插入信号日期\n",
    "        results_.insert(0, 'Date', next_day_)\n",
    "\n",
    "        # 对筛选出的因子赋权\n",
    "        dic_filtered_net_value = {key: dic_all_net_value[key] for key in list_filtered_factor}\n",
    "        weight = pd.DataFrame(linear_weighting_func(dic_filtered_net_value, is0neThird=is0neThird), index=[0])\n",
    "        results_['bullish_probability'] = results_.apply(\n",
    "            lambda row: sum(row[keys] * weight[keys] for keys in weight.keys() if row[keys] > 0), axis=1\n",
    "        )\n",
    "\n",
    "        # 合并结果\n",
    "        combine_results_ = pd.concat([results_, weight], axis=0)\n",
    "        results = pd.concat([results, combine_results_], axis=0)\n",
    "        results_backtesting = pd.concat([results_backtesting, results_], axis=0)\n",
    "\n",
    "        # 将 'bullish_probability' 列移动到最后一列\n",
    "        cols = list(results.columns)\n",
    "        cols.append(cols.pop(cols.index('bullish_probability')))\n",
    "        results = results[cols]\n",
    "        results_backtesting = results_backtesting[cols]\n",
    "\n",
    "    return results, results_backtesting\n",
    "\n",
    "\n",
    "def perform_backtesting(results_backtesting, fromdate=fromdate, todate=todate, e=1, ret_1='ret_x', ret_2='ret_y', probility='bullish_probability', isDraw=True):\n",
    "    def prepare_backtesting_data():\n",
    "        engine = create_engine(\"mysql+pymysql://root:@localhost:3306/meta_data?charset=utf8mb4\")  # 创建数据库连接\n",
    "        # ret_benchmark = pd.read_sql('SELECT cba00101_cs.Date,881001_wi.ret AS ret_x,cba00101_cs.ret AS ret_y  FROM 881001_wi RIGHT JOIN cba00101_cs ON 881001_wi.Date = cba00101_cs.Date', engine)\n",
    "        # 提取基准数据\n",
    "        try:\n",
    "            close_benchmark = pd.read_sql('SELECT cba00101_cs.Date,881001_wi.CLOSE AS close_x,cba00101_cs.CLOSE AS close_y  FROM 881001_wi RIGHT JOIN cba00101_cs ON 881001_wi.Date = cba00101_cs.Date', engine).set_index('Date')\n",
    "        except Exception as e:  # 捕获异常\n",
    "            print(f\"Error connecting to the database or executing SQL: {e}\")\n",
    "            return None\n",
    "        # setting date.index and resample\n",
    "        close_benchmark.index = pd.to_datetime(close_benchmark.index)\n",
    "        close_benchmark_ = close_benchmark.resample('W-MON').last().ffill()\n",
    "        close_benchmark_['ret_x'] = (close_benchmark_['close_x'].shift(-1) - close_benchmark_['close_x']) / close_benchmark_['close_x']\n",
    "        close_benchmark_['ret_y'] = (close_benchmark_['close_y'].shift(-1) - close_benchmark_['close_y']) / close_benchmark_['close_y']\n",
    "        ret_benchmark = close_benchmark_[['ret_x', 'ret_y']]\n",
    "        ret_benchmark.reset_index(inplace=True)\n",
    "        # extract the backtesting period\n",
    "        ret_benchmark['Date'] = pd.to_datetime(ret_benchmark['Date'])\n",
    "        ret_benchmark_ = ret_benchmark[(ret_benchmark['Date'] >= fromdate) & (ret_benchmark['Date'] <= todate)]  # 截取和 bullish posibility 相同的回测区间\n",
    "        # get bullish_probability\n",
    "        df_bullish_posobility = results_backtesting[['Date', 'bullish_probability']]  # get posibility from loop_body function return\n",
    "\n",
    "        # 将 position 和 daily ret 对应起来，需要注意的是我们每一天都有posibility\n",
    "        df_bullish_posobility_ = pd.merge(left=ret_benchmark_, right=df_bullish_posobility, left_on='Date', right_on='Date', how='left')\n",
    "        df_bullish_posobility_.set_index('Date', inplace=True)  # setting\n",
    "        return df_bullish_posobility_\n",
    "\n",
    "    def initialize_first_row(df):\n",
    "        df[['ast_1', 'ast_2', 'nv_stg', 'nv_index']] = 0\n",
    "        df.loc[df.index[0], 'ast_1'] = 1 * df.loc[df.index[0], probility] * (1 + df.loc[df.index[0], ret_1])\n",
    "        df.loc[df.index[0], 'ast_2'] = 1 * (1 - df.loc[df.index[0], probility]) * (1 + df.loc[df.index[0], ret_2])\n",
    "        df.loc[df.index[0], 'nv_stg'] = df.loc[df.index[0], 'ast_1'] + df.loc[df.index[0], 'ast_2']\n",
    "\n",
    "    def update_row(df, inx, prev_row, curr_row):\n",
    "        if curr_row[probility] == 2:\n",
    "            df.loc[inx, 'ast_1'] = prev_row['ast_1'] * (1 + curr_row[ret_1])\n",
    "            df.loc[inx, 'ast_2'] = prev_row['ast_2'] * (1 + curr_row[ret_2])\n",
    "            df.loc[inx, 'nv_stg'] = df.loc[inx, 'ast_1'] + df.loc[inx, 'ast_2']\n",
    "        else:\n",
    "            df.loc[inx, 'ast_1'] = prev_row['nv_stg'] * curr_row[probility] * (1 + curr_row[ret_1])\n",
    "            df.loc[inx, 'ast_2'] = prev_row['nv_stg'] * (1 - curr_row[probility]) * (1 + curr_row[ret_2])\n",
    "            df.loc[inx, 'nv_stg'] = df.loc[inx, 'ast_1'] + df.loc[inx, 'ast_2']\n",
    "\n",
    "    df_bullish_posobility_ = prepare_backtesting_data()\n",
    "    initialize_first_row(df_bullish_posobility_)\n",
    "    df_bullish_posobility_['nv_index'] = (1 + e * df_bullish_posobility_[ret_1] + (1 - e) * df_bullish_posobility_[ret_2]).cumprod()\n",
    "\n",
    "    # 遍历DataFrame\n",
    "    for i, inx in enumerate(df_bullish_posobility_.index):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        prev_row = df_bullish_posobility_.iloc[i - 1]\n",
    "        curr_row = df_bullish_posobility_.iloc[i]\n",
    "        update_row(df_bullish_posobility_, inx, prev_row, curr_row)\n",
    "\n",
    "    if isDraw:\n",
    "        model_text = ratio_analyze(df_bullish_posobility_['nv_stg'], df_bullish_posobility_['bullish_probability'], timeperiod='w')\n",
    "        nv_text = ratio_analyze(df_bullish_posobility_['nv_index'], pd.Series(np.ones(len(df_bullish_posobility_))), timeperiod='w')\n",
    "        draw_sng(df_bullish_posobility_['nv_stg'], df_bullish_posobility_['nv_index'], text='{}\\n{}'.format(model_text, nv_text))\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass\n",
    "    return df_bullish_posobility_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f8cd8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:16:56.612984Z",
     "start_time": "2024-06-17T04:16:56.141107Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://root:@localhost:3306/factors_signal?charset=utf8mb4\")\n",
    "dic_signal = {}  # key:factor_name;value:signal in df format\n",
    "for f in factors_signals:  # 提取signal\n",
    "    temp_signal = pd.read_sql('SELECT * FROM {}'.format(f), engine, index_col='Date')\n",
    "    temp_signal.index = pd.to_datetime(temp_signal.index)  # 规范Date格式\n",
    "    dic_signal[f] = temp_signal\n",
    "\n",
    "# 单独获取 position\n",
    "dic_position = {'zyhgitt': get_position(dic_signal['zyhgitt']),\n",
    "                'zcqlb': get_position(dic_signal['zcqlb'], barShifted=2),\n",
    "                'srclyoy': get_position(dic_signal['srclyoy'], barShifted=2),\n",
    "                'xckpmiidy': get_position(dic_signal['xckpmiidy'], barShifted=2),\n",
    "                'tb10y_diff': get_position(dic_signal['tb10y_diff']),\n",
    "                'tb10y_ttm': get_position(dic_signal['tb10y_ttm']),\n",
    "                'nrfs': get_position(dic_signal['nrfs']),\n",
    "                'roc': get_position(dic_signal['roc']),\n",
    "                'sma': get_position(dic_signal['sma']),\n",
    "                'dma': get_position(dic_signal['dma']),\n",
    "                'dma_ama': get_position(dic_signal['dma_ama']),\n",
    "                'macd': get_position(dic_signal['macd']),\n",
    "                'trix': get_position(dic_signal['trix']),\n",
    "                'bbi': get_position(dic_signal['bbi']),\n",
    "                'bbands': get_position(dic_signal['bbands']),\n",
    "                'cci': get_position(dic_signal['cci']),\n",
    "                'kdj': get_position(dic_signal['kdj']),\n",
    "                'rsi': get_position(dic_signal['rsi']),\n",
    "                'cmo': get_position(dic_signal['cmo']),\n",
    "                'bbands_rzmr': get_position(dic_signal['bbands_rzmr']),\n",
    "                'bbands_iccfe': get_position(dic_signal['bbands_iccfe']),\n",
    "                'bbands_ifcfe': get_position(dic_signal['bbands_ifcfe']),\n",
    "                'volumeratio': get_position(dic_signal['volumeratio']),\n",
    "                'oiratio': get_position(dic_signal['oiratio'])}  # key:factor_name;value: position with DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ad3f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:16:58.403042Z",
     "start_time": "2024-06-17T04:16:58.094281Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark_map = {\n",
    "    12: get_bm('M')[2].reset_index(),\n",
    "    52: get_bm('W-SUN')[2].reset_index(),\n",
    "    250: get_bm('D')[2].reset_index()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2d3e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:22:08.793782Z",
     "start_time": "2024-06-17T04:22:08.586590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79db780c868b48f3a7530806426fc43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建回测区间序列\n",
    "backtesting_period = pd.date_range(start=fromdate, end=todate, freq='W-SUN')\n",
    "engine = create_engine(\"mysql+pymysql://root:@localhost:3306/factors_signal?charset=utf8mb4\")  # 创建数据库连接\n",
    "results = pd.DataFrame()  # 初始化缓存结果\n",
    "results_backtesting = pd.DataFrame()  # 初始化回测结果\n",
    "\n",
    "\n",
    "for i, todate_ in enumerate(tqdm(backtesting_period, desc='PROCESSING')):\n",
    "    \n",
    "    next_day_ = todate_ + datetime.timedelta(days=1)  # 初始化信号日期\n",
    "    fromdate_ = todate_ - datetime.timedelta(days=360)  # 初始化业绩回测起始日期\n",
    "\n",
    "    # 计算因子净值\n",
    "    dic_all_net_value = {\n",
    "        factor_name: get_net_value(dic_position[factor_name], fromdate_, todate_,benchmark_map)\n",
    "        for factor_name in factors_signals\n",
    "    }\n",
    "\n",
    "    # 筛选具有绝对收益的因子\n",
    "    list_filtered_factor = [\n",
    "        key for key in dic_all_net_value.keys()\n",
    "        if dic_all_net_value[key]['nv_idc'].iat[-1] > dic_all_net_value[key]['nv_bm'].iat[-1] or key == 'zcqlb'\n",
    "    ]\n",
    "\n",
    "    # 从数据库中提取信号\n",
    "    results_ = pd.DataFrame()\n",
    "    for table in list_filtered_factor:\n",
    "        query = f\"SELECT `signal` FROM {table} WHERE `Date` BETWEEN '{fromdate_.strftime('%Y-%m-%d')}' AND '{todate_.strftime('%Y-%m-%d')}' ORDER BY `Date` DESC LIMIT 1\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        df.rename(columns={'signal': table}, inplace=True)\n",
    "        results_ = pd.concat([results_, df], axis=1)\n",
    "\n",
    "    # 插入信号日期\n",
    "    results_.insert(0, 'Date', next_day_)\n",
    "\n",
    "    # 对筛选出的因子赋权\n",
    "    dic_filtered_net_value = {key: dic_all_net_value[key] for key in list_filtered_factor}\n",
    "    weight = pd.DataFrame(linear_weighting(dic_filtered_net_value, is0neThird=True), index=[0])\n",
    "    results_['bullish_probability'] = results_.apply(\n",
    "        lambda row: sum(row[keys] * weight[keys] if row[keys] > 0 else 0.5 * weight[keys] if row[keys] == 0 else 0 for keys in weight.keys()), axis=1\n",
    "    )\n",
    "\n",
    "    # 合并结果\n",
    "    combine_results_ = pd.concat([results_, weight], axis=0)\n",
    "    results = pd.concat([results, combine_results_], axis=0)\n",
    "    results_backtesting = pd.concat([results_backtesting, results_], axis=0)\n",
    "\n",
    "    # 将 'bullish_probability' 列移动到最后一列\n",
    "    cols = list(results.columns)\n",
    "    cols.append(cols.pop(cols.index('bullish_probability')))\n",
    "    results = results[cols]\n",
    "    results_backtesting = results_backtesting[cols]\n",
    "\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bullish_posobility_ = perform_backtesting(results_backtesting,isDraw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
